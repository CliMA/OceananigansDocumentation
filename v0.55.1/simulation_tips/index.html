<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Simulation tips · Oceananigans.jl</title><link rel="canonical" href="https://clima.github.io/OceananigansDocumentation/stable/simulation_tips/"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">Oceananigans.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../publications/">Publications</a></li><li><a class="tocitem" href="../installation_instructions/">Installation instructions</a></li><li><a class="tocitem" href="../using_gpus/">Using GPUs</a></li><li><input class="collapse-toggle" id="menuitem-5" type="checkbox"/><label class="tocitem" for="menuitem-5"><span class="docs-label">Examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../generated/one_dimensional_diffusion/">One-dimensional diffusion</a></li><li><a class="tocitem" href="../generated/geostrophic_adjustment/">Geostrophic adjustment</a></li><li><a class="tocitem" href="../generated/two_dimensional_turbulence/">Two-dimensional turbulence</a></li><li><a class="tocitem" href="../generated/internal_wave/">Internal wave</a></li><li><a class="tocitem" href="../generated/convecting_plankton/">Convecting plankton</a></li><li><a class="tocitem" href="../generated/ocean_wind_mixing_and_convection/">Ocean wind mixing and convection</a></li><li><a class="tocitem" href="../generated/langmuir_turbulence/">Langmuir turbulence</a></li><li><a class="tocitem" href="../generated/eady_turbulence/">Eady turbulence</a></li><li><a class="tocitem" href="../generated/kelvin_helmholtz_instability/">Kelvin-Helmholtz instability</a></li><li><a class="tocitem" href="../generated/shallow_water_Bickley_jet/">Shallow water Bickley jet</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-6" type="checkbox"/><label class="tocitem" for="menuitem-6"><span class="docs-label">Model setup</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../model_setup/overview/">Overview</a></li><li><a class="tocitem" href="../model_setup/architecture/">Architecture</a></li><li><a class="tocitem" href="../model_setup/number_type/">Number type</a></li><li><a class="tocitem" href="../model_setup/grids/">Grid</a></li><li><a class="tocitem" href="../model_setup/clock/">Clock</a></li><li><a class="tocitem" href="../model_setup/coriolis/">Coriolis (rotation)</a></li><li><a class="tocitem" href="../model_setup/tracers/">Tracers</a></li><li><a class="tocitem" href="../model_setup/buoyancy_and_equation_of_state/">Buoyancy models and equation of state</a></li><li><a class="tocitem" href="../model_setup/boundary_conditions/">Boundary conditions</a></li><li><a class="tocitem" href="../model_setup/forcing_functions/">Forcing functions</a></li><li><a class="tocitem" href="../model_setup/background_fields/">Background fields</a></li><li><a class="tocitem" href="../model_setup/turbulent_diffusivity_closures_and_les_models/">Turbulent diffusivity closures and LES models</a></li><li><a class="tocitem" href="../model_setup/lagrangian_particles/">Lagrangian particles</a></li><li><a class="tocitem" href="../model_setup/diagnostics/">Diagnostics</a></li><li><a class="tocitem" href="../model_setup/output_writers/">Output writers</a></li><li><a class="tocitem" href="../model_setup/checkpointing/">Checkpointing</a></li><li><a class="tocitem" href="../model_setup/setting_initial_conditions/">Setting initial conditions</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-7" type="checkbox"/><label class="tocitem" for="menuitem-7"><span class="docs-label">Physics</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../physics/navier_stokes_and_tracer_conservation/">Navier-Stokes and tracer conservation equations</a></li><li><a class="tocitem" href="../physics/coriolis_forces/">Coriolis forces</a></li><li><a class="tocitem" href="../physics/buoyancy_and_equations_of_state/">Buoyancy models and equations of state</a></li><li><a class="tocitem" href="../physics/turbulence_closures/">Turbulence closures</a></li><li><a class="tocitem" href="../physics/surface_gravity_waves/">Surface gravity waves and the Craik-Leibovich approximation</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-8" type="checkbox"/><label class="tocitem" for="menuitem-8"><span class="docs-label">Numerical implementation</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../numerical_implementation/pressure_decomposition/">Pressure decomposition</a></li><li><a class="tocitem" href="../numerical_implementation/time_stepping/">Time stepping</a></li><li><a class="tocitem" href="../numerical_implementation/finite_volume/">Finite volume method</a></li><li><a class="tocitem" href="../numerical_implementation/spatial_operators/">Spatial operators</a></li><li><a class="tocitem" href="../numerical_implementation/boundary_conditions/">Boundary conditions</a></li><li><a class="tocitem" href="../numerical_implementation/poisson_solvers/">Poisson solvers</a></li><li><a class="tocitem" href="../numerical_implementation/large_eddy_simulation/">Large eddy simulation</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-9" type="checkbox"/><label class="tocitem" for="menuitem-9"><span class="docs-label">Validation experiments</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../validation/convergence_tests/">Convergence tests</a></li><li><a class="tocitem" href="../validation/lid_driven_cavity/">Lid-driven cavity</a></li><li><a class="tocitem" href="../validation/stratified_couette_flow/">Stratified Couette flow</a></li></ul></li><li class="is-active"><a class="tocitem" href>Simulation tips</a><ul class="internal"><li><a class="tocitem" href="#General-(CPU/GPU)-simulation-tips"><span>General (CPU/GPU) simulation tips</span></a></li><li><a class="tocitem" href="#GPU-simulation-tips"><span>GPU simulation tips</span></a></li></ul></li><li><a class="tocitem" href="../gallery/">Gallery</a></li><li><a class="tocitem" href="../benchmarks/">Performance benchmarks</a></li><li><a class="tocitem" href="../contributing/">Contributor&#39;s guide</a></li><li><input class="collapse-toggle" id="menuitem-14" type="checkbox"/><label class="tocitem" for="menuitem-14"><span class="docs-label">Appendix</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../appendix/staggered_grid/">Staggered grid</a></li><li><a class="tocitem" href="../appendix/fractional_step/">Fractional step method</a></li></ul></li><li><a class="tocitem" href="../references/">References</a></li><li><a class="tocitem" href="../library/">Library</a></li><li><a class="tocitem" href="../function_index/">Function index</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Simulation tips</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Simulation tips</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/CliMA/Oceananigans.jl/blob/master/docs/src/simulation_tips.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Simulation-tips"><a class="docs-heading-anchor" href="#Simulation-tips">Simulation tips</a><a id="Simulation-tips-1"></a><a class="docs-heading-anchor-permalink" href="#Simulation-tips" title="Permalink"></a></h1><p>In Oceananigans we try to do most of the optimizing behind the scenes, that way the average user doesn&#39;t have to worry about details when setting up a simulation. However, there&#39;s just so much optimization that can be done in the source code. Because of Oceananigans script-based interface, the user has to be aware of some things when writing the simulation script in order to take full advantage of Julia&#39;s speed. Furthermore, in case of more complex GPU runs, some details could sometimes prevent your simulation from running altogether. While Julia knowledge is obviously desirable here, a user that is unfamiliar with Julia can get away with efficient simulations by learning a few rules of thumb. It is nonetheless recommended that users go through Julia&#39;s <a href="https://docs.julialang.org/en/v1/manual/performance-tips/">performance tips</a>, which contains more in-depth explanations of some of the aspects discussed here.</p><h2 id="General-(CPU/GPU)-simulation-tips"><a class="docs-heading-anchor" href="#General-(CPU/GPU)-simulation-tips">General (CPU/GPU) simulation tips</a><a id="General-(CPU/GPU)-simulation-tips-1"></a><a class="docs-heading-anchor-permalink" href="#General-(CPU/GPU)-simulation-tips" title="Permalink"></a></h2><h3 id="Avoid-global-variables-whenever-possible"><a class="docs-heading-anchor" href="#Avoid-global-variables-whenever-possible">Avoid global variables whenever possible</a><a id="Avoid-global-variables-whenever-possible-1"></a><a class="docs-heading-anchor-permalink" href="#Avoid-global-variables-whenever-possible" title="Permalink"></a></h3><p>In general using a <a href="https://docs.julialang.org/en/v1/manual/variables-and-scoping/#Global-Scope">global variable</a> (which can be loosely defined as a variable defined in the main script) inside functions slows down the code. One way to circumvent this is to always <a href="https://docs.julialang.org/en/v1/manual/performance-tips/#Avoid-global-variables">use local variables or pass them as arguments to functions</a>. This helps the compiler optimize the code.</p><p>Another way around this is to <a href="https://docs.julialang.org/en/v1/manual/performance-tips/#Avoid-global-variables">define global variables as constants whenever possible</a>. One thing to keep in mind when doing this is that when a <code>const</code> is defined, its value can&#39;t be changed until you restart the Julia session. So this latter approach is good for production-ready code, but may be undesirable in the early stages of development while you still have to change the parameters of the simulation for exploration.</p><p>It is especially important to avoid global variables in functions that are meant to be executed in GPU kernels (such as functions defining boundary conditions and forcings). Otherwise the Julia GPU compiler can fail with obscure errors. This is explained in more detail in the GPU simulation tips section below.</p><h3 id="Consider-inlining-small-functions"><a class="docs-heading-anchor" href="#Consider-inlining-small-functions">Consider inlining small functions</a><a id="Consider-inlining-small-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Consider-inlining-small-functions" title="Permalink"></a></h3><p>Inlining is when the compiler <a href="https://en.wikipedia.org/wiki/Inline_expansion">replaces a function call with the body of the function that is being called before compiling</a>. The advantage of inlining (which in julia can be done with the <a href="https://docs.julialang.org/en/v1/devdocs/meta/"><code>@inline</code> macro</a>) is that gets rid of the time spent calling the function. The Julia compiler automatically makes some calls as to what functions it should or shouldn&#39;t inline, but you can force a function to be inlined by including the macro <code>@inline</code> before its definition. This is more suited for small functions that are called often. Here&#39;s an example of an implementation of the Heaviside function that forces it to be inlined:</p><pre><code class="language-julia">@inline heaviside(X) = ifelse(X &lt; 0, zero(X), one(X))</code></pre><p>In practice it&#39;s hard to say whether inlining a function will bring runtime benefits <em>with certainty</em>, since Julia and KernelAbstractions.jl (needed for GPU runs) already inline some functions automatically. However, it is generally a good idea to at least investigate this aspect in your code as the benefits can potentially be significant.</p><h2 id="GPU-simulation-tips"><a class="docs-heading-anchor" href="#GPU-simulation-tips">GPU simulation tips</a><a id="GPU-simulation-tips-1"></a><a class="docs-heading-anchor-permalink" href="#GPU-simulation-tips" title="Permalink"></a></h2><p>Running on GPUs can be very different from running on CPUs. Oceananigans makes most of the necessary changes in the background, so that for very simple simulations changing between CPUs and GPUs is just a matter of changing the <code>architecture</code> argument in the model from <code>CPU()</code> to <code>GPU()</code>. However, for more complex simulations some care needs to be taken on the part of the user. While knowledge of GPU computing (and Julia) is again desirable, an inexperienced user can also achieve high efficiency in GPU simulations by following a few simple principles.</p><h3 id="Variables-that-need-to-be-used-in-GPU-computations-need-to-be-defined-as-constants"><a class="docs-heading-anchor" href="#Variables-that-need-to-be-used-in-GPU-computations-need-to-be-defined-as-constants">Variables that need to be used in GPU computations need to be defined as constants</a><a id="Variables-that-need-to-be-used-in-GPU-computations-need-to-be-defined-as-constants-1"></a><a class="docs-heading-anchor-permalink" href="#Variables-that-need-to-be-used-in-GPU-computations-need-to-be-defined-as-constants" title="Permalink"></a></h3><p>Any global variable that needs to be accessed by the GPU needs to be a constant or the simulation will crash. This includes any variables used in forcing functions and boundary conditions. For example, if you define a boundary condition like the example below and run your simulation on a GPU you&#39;ll get an error.</p><pre><code class="language-julia">dTdz = 0.01 # K m⁻¹
T_bcs = TracerBoundaryConditions(grid,
                                 bottom = GradientBoundaryCondition(dTdz))</code></pre><p>However, if you define <code>dTdz</code> as a constant by replacing the first line with <code>const dTdz = 0.01</code>, then (provided everything else is done properly) your run will be successful.</p><h3 id="Complex-diagnostics-using-ComputedFields-may-not-work-on-GPUs"><a class="docs-heading-anchor" href="#Complex-diagnostics-using-ComputedFields-may-not-work-on-GPUs">Complex diagnostics using <code>ComputedField</code>s may not work on GPUs</a><a id="Complex-diagnostics-using-ComputedFields-may-not-work-on-GPUs-1"></a><a class="docs-heading-anchor-permalink" href="#Complex-diagnostics-using-ComputedFields-may-not-work-on-GPUs" title="Permalink"></a></h3><p><code>ComputedField</code>s are the most convenient way to calculate diagnostics for your simulation. They will always work on CPUs, but when their complexity is high (in terms of number of abstract operations) the compiler can&#39;t translate them into GPU code and they fail for GPU runs. (This limitation is discussed  in <a href="https://github.com/CliMA/Oceananigans.jl/issues/1241">this Github issue</a> and contributors are welcome.) For example, in the example below, calculating <code>u²</code> works in both CPUs and GPUs, but calculating  <code>KE</code> only works on CPUs:</p><pre><code class="language-julia">u, v, w = model.velocities
u² = ComputedField(u^2)
KE = ComputedField((u^2 + v^2 + w^2)/2)
compute!(u²)
compute!(KE)</code></pre><p>There are two approaches to bypass this issue. The first is to nest <code>ComputedField</code>s. For example, we can make <code>KE</code> be successfully computed on GPUs by defining it as</p><pre><code class="language-julia">u, v, w = model.velocities
u² = ComputedField(u^2)
v² = ComputedField(v^2)
w² = ComputedField(w^2)
u²plusv² = ComputedField(u² + v²)
KE = ComputedField((u²plusv² + w²)/2)
compute!(KE)</code></pre><p>This is a simple workaround that is especially suited for the development stage of a simulation. However, when running this, the code will iterate over the whole domain 5 times to calculate <code>KE</code> (one for each computed field defined), which is not very efficient.</p><p>A different way to calculate <code>KE</code> is by using <code>KernelComputedField</code>s, where the user manually specifies the computing kernel to the compiler. The advantage of this method is that it&#39;s more efficient (the code will only iterate once over the domain in order to calculate <code>KE</code>), but the disadvantage is that this requires that the has some knowledge of Oceananigans operations and how they should be performed on a C-grid. For example calculating <code>KE</code> with this approach would look like this:</p><pre><code class="language-julia">using Oceananigans.Operators
using KernelAbstractions: @index, @kernel
using Oceananigans.Grids: Center, Face
using Oceananigans.Fields: KernelComputedField

@inline ψ²(i, j, k, grid, ψ) = @inbounds ψ[i, j, k]^2

@kernel function kinetic_energy_ccc!(tke, grid, u, v, w)
    i, j, k = @index(Global, NTuple)
    @inbounds tke[i, j, k] = (
                              ℑxᶜᵃᵃ(i, j, k, grid, ψ², u) + # Calculates u^2 using function ψ² and then interpolates in x to grid center
                              ℑyᵃᶜᵃ(i, j, k, grid, ψ², v) + # Calculates v^2 using function ψ² and then interpolates in y to grid center
                              ℑzᵃᵃᶜ(i, j, k, grid, ψ², w)   # Calculates w^2 using function ψ² and then interpolates in z to grid center
                             ) / 2
end

KE = KernelComputedField(Center, Center, Center, kinetic_energy_ccc!, model;
                         computed_dependencies=(u, v, w))</code></pre><p>It may be useful to know that there are some kernels already defined for commonly-used diagnostics in packages that are companions to Oceananigans. For example <a href="https://github.com/tomchor/Oceanostics.jl/blob/13d2ba5c48d349c5fce292b86785ce600cc19a88/src/TurbulentKineticEnergyTerms.jl#L23-L30">Oceanostics.jl</a> and <a href="https://github.com/CliMA/LESbrary.jl/blob/master/src/TurbulenceStatistics/shear_production.jl">LESbrary.jl</a>. Users should first look there before writing any kernel by hand and are always welcome to <a href="https://github.com/CliMA/Oceananigans.jl/issues/new">start an issue on Github</a> if they need help to write a different kernel.</p><h3 id="Try-to-decrease-the-memory-use-of-your-runs"><a class="docs-heading-anchor" href="#Try-to-decrease-the-memory-use-of-your-runs">Try to decrease the memory-use of your runs</a><a id="Try-to-decrease-the-memory-use-of-your-runs-1"></a><a class="docs-heading-anchor-permalink" href="#Try-to-decrease-the-memory-use-of-your-runs" title="Permalink"></a></h3><p>GPU runs are generally memory-limited. As an example, a state-of-the-art Tesla V100 GPU has 32GB of memory, which is enough to fit, on average, a simulation with about 100 million points –- a bit smaller than a 512-cubed simulation. (The precise number depends on many other things, such as the number of tracers simulated, as well as the diagnostics that are calculated.) This means that it is especially important to be mindful of the size of your runs when running Oceananigans on GPUs and it is generally good practice to decrease the memory required for your runs. Below are some useful tips to achieve this</p><ul><li>Use the <a href="https://developer.nvidia.com/nvidia-system-management-interface"><code>nvidia-smi</code></a> command line utility to monitor the memory usage of the GPU. It should tell you how much memory there is on your GPU and how much of it you&#39;re using.</li><li>Try to use higher-order advection schemes. In general when you use a higher-order scheme you need fewer grid points to achieve the same accuracy that you would with a lower-order one. Oceananigans provides two high-order advection schemes: 5th-order WENO method (WENO5) and 3rd-order upwind.</li><li>Manually define scratch space to be reused in diagnostics. By default, every time a user-defined diagnostic is calculated the compiler reserves a new chunk of memory for that calculation, usually called scratch space. In general, the more diagnostics, the more scratch space needed and the bigger the memory requirements. However, if you explicitly create a scratch space and pass that same scratch space for as many diagnostics as you can, you minimize the memory requirements of your calculations by reusing the same memory chunk. As an example, you can see scratch space being created <a href="https://github.com/CliMA/LESbrary.jl/blob/cf31b0ec20219d5ad698af334811d448c27213b0/examples/three_layer_ constant_fluxes.jl#L380-L383">here</a> and then being used in calculations <a href="https://github.com/CliMA/LESbrary.jl/blob/cf31b0ec20219d5ad698af334811d448c27213b0/src/TurbulenceStatistics/first_through_third_order.jl#L109-L112">here</a>.</li></ul><h3 id="Arrays-in-GPUs-are-usually-different-from-arrays-in-CPUs"><a class="docs-heading-anchor" href="#Arrays-in-GPUs-are-usually-different-from-arrays-in-CPUs">Arrays in GPUs are usually different from arrays in CPUs</a><a id="Arrays-in-GPUs-are-usually-different-from-arrays-in-CPUs-1"></a><a class="docs-heading-anchor-permalink" href="#Arrays-in-GPUs-are-usually-different-from-arrays-in-CPUs" title="Permalink"></a></h3><p>On the CPU Oceananigans.jl uses regular <code>Array</code>s, but on the GPU it has to use <code>CuArray</code>s from the CUDA.jl package. You might need to keep this difference in mind when using arrays to <code>set!</code> initial conditions or when using arrays to provide boundary conditions and forcing functions.</p><p>To learn more about working with <code>CuArray</code>s, see the <a href="https://juliagpu.github.io/CUDA.jl/dev/usage/array/">array programming</a> section of the CUDA.jl documentation.</p><p>Something to keep in mind when working with <code>CuArray</code>s is that you do not want to set or get/access elements of a <code>CuArray</code> outside of a kernel. Doing so invokes scalar operations in which individual elements are copied from or to the GPU for processing. This is very slow and can result in huge slowdowns. For this reason, Oceananigans.jl disables CUDA scalar operations by default.</p><p>See the <a href="https://juliagpu.github.io/CUDA.jl/dev/usage/workflow/#UsageWorkflowScalar">scalar indexing</a> section of the CUDA.jl documentation for more information on scalar indexing.</p><p>Sometimes you need to perform scalar operations on <code>CuArray</code>s in which case you may want to temporarily allow scalar operations with the <code>CUDA.@allowscalar</code> macro or by calling <code>CUDA.allowscalar(true)</code>.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../validation/stratified_couette_flow/">« Stratified Couette flow</a><a class="docs-footer-nextpage" href="../gallery/">Gallery »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Wednesday 21 April 2021 16:56">Wednesday 21 April 2021</span>. Using Julia version 1.5.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
